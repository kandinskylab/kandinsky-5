{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6e8cf7",
   "metadata": {},
   "source": [
    "### üìÅ Available LoRa Models\n",
    "\n",
    "| Model Size | Motion Type | LoRa Name | Description |\n",
    "|-------|-------------|-----------|-------------|\n",
    "| Lite, Pro | Object Rotation | `Microwave-right` | Rotates object ~360¬∞ to the right over 5 seconds |\n",
    "| Lite, Pro | Object Rotation | `Microwave-left` | Rotates object ~360¬∞ to the left over 5 seconds |\n",
    "| Lite, Pro | Camera Movement | `Arc-right` | Camera arcs ~360¬∞ around object to the right over 5 seconds |\n",
    "| Lite, Pro | Camera Movement | `Arc-left` | Camera arcs ~360¬∞ around object to the left over 5 seconds |\n",
    "| Lite | Camera Movement | `Dolly-in` | Camera moves forward toward subject |\n",
    "| Lite | Camera Movement | `Dolly-out` | Camera moves backward from subject |\n",
    "| Lite | Camera Movement | `Truck-right` | Camera tracks horizontally to the right |\n",
    "| Lite | Camera Movement | `Truck-left` | Camera tracks horizontally to the left |\n",
    "\n",
    "<br>\n",
    "\n",
    ">  Note:\n",
    "> 1. For optimal performance, select an appropriate LoRa for the **t2v** (text-to-video) or **i2v** (image-to-video) modality.  \n",
    ">    We named our LoRas using the template: `kandinskylab/Kandinsky-5.0-{Modality}-{Model_Size}-LoRa-{LoRa_Name}` where `Modality` is either `I2V` or `T2V`.\n",
    "> 2. Additional camera movements in the **Pro** model can be achieved directly via the prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "from kandinsky import get_I2V_pipeline\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99a497",
   "metadata": {},
   "source": [
    "### Load pipe \n",
    "first, ensure that you have downloaded the models using `download_models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5198a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = get_I2V_pipeline(\n",
    "    device_map={\"dit\": \"cuda:0\", \"vae\": \"cuda:0\", \"text_embedder\": \"cuda:0\"},\n",
    "\tconf_path=\"./configs/k5_lite_i2v_5s_sft_sd.yaml\",\n",
    "    magcache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ce030",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Download LoRa adapter from HuggingFaceü§ó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = './weights'\n",
    "lora_name = 'Microwave-right'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-I2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e988366",
   "metadata": {},
   "source": [
    "Load the adapter into the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_name = 'test_diffusers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path=os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6fce3",
   "metadata": {},
   "source": [
    "> Note: <br>\n",
    "> The trigger words we use are stored in the LoRA safetensors metadata. They are automatically concatenated with prompts during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.peft_triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1b081",
   "metadata": {},
   "source": [
    "Generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './outputs/loras/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image = \"assets/test_image.jpg\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'),\n",
    "    seed=12345,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50dc504",
   "metadata": {},
   "source": [
    "Download another adapter and switch to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e074490",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_name = 'Microwave-left'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-I2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")\n",
    "\n",
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_image.jpg\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19752f7d",
   "metadata": {},
   "source": [
    "Switch to the previous loaded LoRa adapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_lora_name = 'Microwave-right'\n",
    "pipe.set_adapter(prev_lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b373622",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_image.jpg\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v2.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8538c3",
   "metadata": {},
   "source": [
    "Disable all adapters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.disable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_image.jpg\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_default.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_default.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df629af",
   "metadata": {},
   "source": [
    "Set already loaded adapter again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee69802",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_adapter(prev_lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_image.jpg\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v3.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v3.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53761aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
