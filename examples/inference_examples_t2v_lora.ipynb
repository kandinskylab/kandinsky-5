{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b07c8ef",
   "metadata": {},
   "source": [
    "### üìÅ Available LoRa Models\n",
    "\n",
    "| Model Size | Motion Type | LoRa Name | Description |\n",
    "|-------|-------------|-----------|-------------|\n",
    "| Lite, Pro | Object Rotation | `Microwave-right` | Rotates object ~360¬∞ to the right over 5 seconds |\n",
    "| Lite, Pro | Object Rotation | `Microwave-left` | Rotates object ~360¬∞ to the left over 5 seconds |\n",
    "| Lite, Pro | Camera Movement | `Arc-right` | Camera arcs ~360¬∞ around object to the right over 5 seconds |\n",
    "| Lite, Pro | Camera Movement | `Arc-left` | Camera arcs ~360¬∞ around object to the left over 5 seconds |\n",
    "| Lite | Camera Movement | `Dolly-in` | Camera moves forward toward subject |\n",
    "| Lite | Camera Movement | `Dolly-out` | Camera moves backward from subject |\n",
    "| Lite | Camera Movement | `Truck-right` | Camera tracks horizontally to the right |\n",
    "| Lite | Camera Movement | `Truck-left` | Camera tracks horizontally to the left |\n",
    "\n",
    "<br>\n",
    "\n",
    ">  Note:\n",
    "> 1. For optimal performance, select an appropriate LoRa for the **t2v** (text-to-video) or **i2v** (image-to-video) modality.  \n",
    ">    We named our LoRas using the template: `kandinskylab/Kandinsky-5.0-{Modality}-{Model_Size}-LoRa-{LoRa_Name}` where `Modality` is either `I2V` or `T2V`.\n",
    "> 2. Additional camera movements in the **Pro** model can be achieved directly via the prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135f0af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention 2 is found\n",
      "FlashAttention 3 is found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download\n",
    "from kandinsky import get_T2V_pipeline\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5af47",
   "metadata": {},
   "source": [
    "### Load pipe \n",
    "first, ensure that you have downloaded the models using `download_models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5198a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8587585832cf40899eef8deeccd473dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "pipe = get_T2V_pipeline(\n",
    "    device_map={\"dit\": \"cuda:0\", \"vae\": \"cuda:0\", \"text_embedder\": \"cuda:0\"},\n",
    "    conf_path=\"./configs/k5_lite_t2v_5s_sft_sd.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673000c4",
   "metadata": {},
   "source": [
    "#### Download LoRa adapter from HuggingFaceü§ó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f28397b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44c6b8655ed4c0f9d17c1906aaecbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997ba36dd7184b42b3bb627a7d3fd1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_lora.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b96b87322f84730ab5616bfe687b7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cache_dir = './weights'\n",
    "lora_name = 'Microwave-right'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-T2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484cf6ac",
   "metadata": {},
   "source": [
    "Load the adapter into the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dd4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08230234",
   "metadata": {},
   "source": [
    "Note: The trigger words we use are stored in the LoRA safetensors metadata. They are automatically concatenated with prompts during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b4a214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Microwave-right': 'M1CR0W4V3 r0t4tION, 360-degree rotation. '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.peft_triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725a88f",
   "metadata": {},
   "source": [
    "Generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e2a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:46<00:00,  4.53s/it] \n",
      "/home/jovyan/shares/SR008.fs2/me/envs/kandi5/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/t2v_lite_Microwave-right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = './outputs/loras/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d262fc",
   "metadata": {},
   "source": [
    "Download another adapter and switch to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd1fa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebc5bd0532f4084a4ecfb13f0b19c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_name = 'Microwave-left'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-T2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")\n",
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bf5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:33<00:00,  4.26s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/t2v_lite_Microwave-left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b2ca3",
   "metadata": {},
   "source": [
    "Switch to the previous LoRa adapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7116db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_lora_name = 'Microwave-right'\n",
    "pipe.set_adapter(prev_lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b373622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:31<00:00,  4.23s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/t2v_lite_Microwave-right_v2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f't2v_lite_{prev_lora_name}_v2.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f't2v_lite_{prev_lora_name}_v2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ebee7",
   "metadata": {},
   "source": [
    "Disable all adapters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53524ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.disable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b460d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:21<00:00,  4.03s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/default.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f'default.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'default.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a252a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
